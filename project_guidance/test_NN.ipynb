{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import camera_tools as ct\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.function_base import linspace\n",
    "from FableAPI.fable_init import api\n",
    "\n",
    "api.setup(blocking=True)\n",
    "moduleids = api.discoverModules()\n",
    "print(\"Module IDs: \", moduleids)\n",
    "moduleID = moduleids[0]\n",
    "print(\"Battery level:\",api.getBattery(moduleID),\"%\")\n",
    "\n",
    "#Calibrate the camera to detect green box, if you haven't done this calibration before\n",
    "low_green, high_green = ct.colorpicker()\n",
    "print(low_green)\n",
    "print(high_green)\n",
    "#Check whether the camera detects the green object properly\n",
    "cam = ct.prepare_camera()\n",
    "img = ct.capture_image(cam)\n",
    "ct.show_camera(cam)\n",
    "\n",
    "#Use this function to calculate Y (angular) position errors \n",
    "# Y (angular) positions\n",
    "def readAngleFilesAndCollectErrors(fileName):\n",
    "    angleDataFrame = pd.read_csv(fileName)\n",
    "    desired_column = angleDataFrame.columns[0]\n",
    "    angle_error_list = []\n",
    "    for i in range(1,len(angleDataFrame)):\n",
    "        current_data_element = angleDataFrame[desired_column][i]\n",
    "        previous_data_element = angleDataFrame[desired_column][i-1]\n",
    "        #TODO: Calculate the Y (angular) position error(say current_error) as the difference between \n",
    "        # the current Y (angular) position and previous Y (angular) position\n",
    "        current_error = current_data_element - previous_data_element\n",
    "        #print(current_data_element,\" \", previous_data_element, \" \", current_error)\n",
    "        angle_error_list = angle_error_list + [current_error]\n",
    "    return angle_error_list\n",
    "\n",
    "#Use this function to calculate errors between x and y coordinates\n",
    "def readXYCoordsFilesAndCollectErrors(fileName):\n",
    "    xyCoordsDataFrame = pd.read_csv(fileName)\n",
    "    x_col_name = xyCoordsDataFrame.columns[0]\n",
    "    y_col_name = xyCoordsDataFrame.columns[1]\n",
    "    x_pos_error_list = []\n",
    "    y_pos_error_list = []\n",
    "    for i in range(1,len(xyCoordsDataFrame)):\n",
    "        current_data_element_x = xyCoordsDataFrame[x_col_name][i]\n",
    "        current_data_element_y = xyCoordsDataFrame[y_col_name][i]\n",
    "        previous_data_element_x = xyCoordsDataFrame[x_col_name][i-1]\n",
    "        previous_data_element_y = xyCoordsDataFrame[y_col_name][i-1]\n",
    "        error_x_pos = current_data_element_x - previous_data_element_x \n",
    "        error_y_pos = current_data_element_y - previous_data_element_y\n",
    "        x_pos_error_list = x_pos_error_list + [error_x_pos]\n",
    "        y_pos_error_list = y_pos_error_list + [error_y_pos] \n",
    "    return [x_pos_error_list,y_pos_error_list]\n",
    "\n",
    "#Read the provided files and load the calculated errors into to appropriate lists as follows\n",
    "angle_error_list_1 = readAngleFilesAndCollectErrors(\"angles_1.csv\")\n",
    "x_pos_error_list_1,y_pos_error_list_1 = readXYCoordsFilesAndCollectErrors(\"xyCoords_1.csv\")\n",
    "\n",
    "#merge both angle_error_list_1 and angle_error_list_2 to a single list and make it a numpy array called 'angle_error_array'\n",
    "angle_error_array = np.array(angle_error_list_1)\n",
    "#merge both x_pos_error_list_1 and x_pos_error_list_2 to a single list and make it a numpy array called 'x_coord_error_array'\n",
    "x_coord_error_array = np.array(x_pos_error_list_1)\n",
    "#merge both y_pos_error_list_1 and y_pos_error_list_2 to a single list and make it a numpy array called 'y_coord_error_array'\n",
    "y_coord_error_array = np.array(y_pos_error_list_1)\n",
    "\n",
    "\n",
    "\n",
    "# Here we use 80% of the collected data  as the training set and 20% of the collected data as test set.\n",
    "#TODO: Assign different propotions of the collected data set and test set and check how the test set error varies of the \n",
    "#Neural Network\n",
    "data =  np.vstack((x_coord_error_array,y_coord_error_array)).T\n",
    "target = np.vstack(angle_error_array)\n",
    "data_input_tensor = torch.tensor(data.tolist()).float()\n",
    "data_target_tensor = torch.tensor(target.tolist()).float()\n",
    "data_with_target = torch.cat((data_input_tensor,data_target_tensor),1)\n",
    "#TODO: what is the importance of using DataLoader utility function here?\n",
    "loader= torch.utils.data.DataLoader(data_with_target,\n",
    "                                     batch_size=data_with_target.size()[0], shuffle=True,\n",
    "                                     num_workers=0)\n",
    "#training set\n",
    "train_set = []\n",
    "#test set\n",
    "test_set = []\n",
    "for i in iter(loader):\n",
    "    train_set_index = (int)(np.round(i.shape[0]*0.8))\n",
    "    train_set = i[:train_set_index,:]\n",
    "    test_set = i[train_set_index:,:]\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "#Defining Neural Network Model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden1,n_hidden2,n_output):\n",
    "        super(NN,self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature,n_hidden1)\n",
    "        # self.do1 = torch.nn.Dropout(0.15)\n",
    "        #self.relu1 = torch.nn.LeakyReLU()\n",
    "        #self.bn1 = torch.nn.BatchNorm1d(n_hidden1,affine=False)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden1,n_hidden2)\n",
    "        #self.bn2 = torch.nn.BatchNorm1d(n_hidden2,affine=False)\n",
    "        #self.relu2 = torch.nn.LeakyReLU()\n",
    "        # self.do2 = torch.nn.Dropout(0.1)\n",
    "        self.predict = torch.nn.Linear(n_hidden2,n_output)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "train_set_inputs = train_set[:,:2]\n",
    "#TODO: calculate the mean value of the train_set_inputs.\n",
    "mean_of_train_input = torch.mean(train_set_inputs,0)\n",
    "#standard deviation of the train set inputs.\n",
    "std_of_the_train_input = torch.std(train_set_inputs,0)\n",
    "#here we normalize the inputs of the neural network. What is the importance of that?\n",
    "normalized_train_set_inputs = (train_set_inputs - mean_of_train_input)/std_of_the_train_input\n",
    "#targets of the training set\n",
    "train_set_targets = train_set[:,2][:,np.newaxis]\n",
    "print(normalized_train_set_inputs.shape)\n",
    "print(train_set_targets.shape)\n",
    "\n",
    "#reload the your best neural network model with saved parameters\n",
    "n_hidden1 = torch.load('best_nn_hidden1.pth')\n",
    "n_hidden2 = torch.load('best_nn_hidden2.pth')\n",
    "NN_model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "NN_model.load_state_dict(torch.load('best_nn_model.pth'))\n",
    "#TODO: Extract inputs of the test_set\n",
    "test_set_inputs = test_set[:,:2]\n",
    "#TODO: Extract test set targets from the test_set\n",
    "test_set_targets = test_set[:,2][:,np.newaxis]\n",
    "#TODO: Normalize test set inputs by using the mean and standard deviation of the inputs of the training set\n",
    "mean_training_inputs = torch.load('best_mean.pth')\n",
    "std_training_inputs = torch.load('best_std.pth')\n",
    "normalized_test_set_inputs = (test_set_inputs - mean_training_inputs)/std_training_inputs\n",
    "#TODO: feed the normalized test set inputs to the Neural Network model and obtain the prediction for the test set.\n",
    "prediction_test = NN_model(normalized_test_set_inputs)\n",
    "print(prediction_test.shape)\n",
    "\n",
    "# Grab an image and locate the largest green object:\n",
    "def getPos():\n",
    "    cam = ct.prepare_camera()\n",
    "    while True:\n",
    "        img = ct.capture_image(cam)\n",
    "        x, y = ct.locate(img)\n",
    "        if x is not None:\n",
    "            break\n",
    "    # print(\"Now the camera is done adjusting!\")\n",
    "    X,Y = [],[] \n",
    "    for _ in range(10):\n",
    "        img = ct.capture_image(cam)\n",
    "        x, y = ct.locate(img)\n",
    "        # print(x, y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    cam.release()\n",
    "    X = np.rint(np.mean(np.asarray(X))).astype(int)\n",
    "    Y = np.rint(np.mean(np.asarray(Y))).astype(int)\n",
    "    return (X,Y)\n",
    "\n",
    "def squaredist(target_x,target_y,x,y):\n",
    "    a = np.square(np.abs(target_x-x))\n",
    "    b = np.square(np.abs(target_y-y))\n",
    "    return np.sqrt(a+b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ERROR THRESHOLD\n",
    "err_treshold = 5\n",
    "\n",
    "#Here we implement the control loop which is having Neural Network as the controller.\n",
    "#In this case we donot integrate CMAC to the control loop\n",
    "def ControlLoopWithNNWithoutCMAC(target__x_coordinate,target__y_coordinate):\n",
    "    number_of_iterations_for_convergence = 0\n",
    "    #TODO:Intialize your best neural network model and load the saved paramemeters\n",
    "    NN_model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "    NN_model.load_state_dict(torch.load('best_nn_model.pth'))\n",
    "    mean_training_inputs = torch.load('best_mean.pth')\n",
    "    std_training_inputs = torch.load('best_std.pth')\n",
    "\n",
    "    #TODO: Obtain the x and y coodinates of the green box placed on the end effector of the robot\n",
    "    robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "    # Here we loop for 50 iterations assuming that \n",
    "    # the controller should achieve the desired target within atmost 50 iterations\n",
    "    x_error_list,y_error_list, sqrt_error_list = [],[],[]\n",
    "    for i in range(20):\n",
    "        print(\"Curr_pos: \",robot_current_X_pos, robot_current_Y_pos)\n",
    "        print(\"Curr_target:\",target__x_coordinate,target__y_coordinate )\n",
    "        \n",
    "        x_coord_error = target__x_coordinate - robot_current_X_pos\n",
    "        y_coord_error = target__y_coordinate - robot_current_Y_pos\n",
    "        print(\"Error_x: \",x_coord_error)\n",
    "        #Here if the errors are less than twenty pixels we assume robot reaches the target. \n",
    "        # However you can choose any reasonable threshold value instead of 20.\n",
    "        if (np.abs(x_coord_error) < err_treshold and np.abs(y_coord_error) < err_treshold):\n",
    "            print(\"Number of iterations for convergence = \", number_of_iterations_for_convergence)\n",
    "            x_error_list.append(np.abs(x_coord_error))\n",
    "            y_error_list.append(np.abs(y_coord_error))\n",
    "            sqrt_error_list.append(squaredist(target__x_coordinate,target__y_coordinate,robot_current_X_pos,robot_current_Y_pos))\n",
    "            break\n",
    "\n",
    "        # Normalize the input to the Neural network model using meaning and variance of the training set inputs\n",
    "        xy_input_nn_model = torch.tensor([x_coord_error,y_coord_error]).float()\n",
    "        normalize_xy_input_nn_model = (xy_input_nn_model - mean_training_inputs)/std_training_inputs\n",
    "        print(normalize_xy_input_nn_model)\n",
    "        # Predict \n",
    "        prediction_for_Y_pos_increment = NN_model(normalize_xy_input_nn_model)\n",
    "        print(\"Increment_y: \",prediction_for_Y_pos_increment[0])\n",
    "        \n",
    "        # Get current motorY angle\n",
    "        currAngY = api.getPos('Y',moduleID)\n",
    "        print(\"Curr_angleY: \",currAngY)\n",
    "        \n",
    "        # Set the next position of the robot to (-90,robot_next_Y_pos) using the setPos function of the fable.\n",
    "        api.setPos(-90,currAngY + prediction_for_Y_pos_increment, moduleID)\n",
    "        api.sleep(1.5)\n",
    "        print(\"AngleY after: \",api.getPos('Y',moduleID))\n",
    "        \n",
    "        # Get current position of the robot in the camera frame\n",
    "        robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "        number_of_iterations_for_convergence = number_of_iterations_for_convergence + 1\n",
    "        x_error_list.append(np.abs(x_coord_error))\n",
    "        y_error_list.append(np.abs(y_coord_error))\n",
    "        sqrt_error_list.append(squaredist(target__x_coordinate,target__y_coordinate,robot_current_X_pos,robot_current_Y_pos))\n",
    "        print(\"\\n\")\n",
    "    return number_of_iterations_for_convergence,x_error_list,y_error_list,sqrt_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE RANDOM TARGET POINT\n",
    "targetList = []\n",
    "for i in range(10):\n",
    "    if i < 5:\n",
    "        angY = np.random.randint(-90,40)\n",
    "        api.setPos(-90,angY,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        targetList.append(getPos())\n",
    "    else:\n",
    "        angY = np.random.randint(-40,90)\n",
    "        api.setPos(-90,angY,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        targetList.append(getPos())\n",
    "torch.save(targetList, 'targetList1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT TARGET POINTS\n",
    "targetList = torch.load('targetList1.pth')\n",
    "targetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP THROUGHT TARGET POINT\n",
    "itList = []\n",
    "eeList = []\n",
    "x_error_list, y_error_list, sqrt_error_list = [],[],[]\n",
    "i=0\n",
    "for el in targetList:\n",
    "    if i < 5 :\n",
    "        api.setPos(-90,90,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        i+=1\n",
    "    else:\n",
    "        api.setPos(-90,-90,moduleID)\n",
    "        api.sleep(1.5)\n",
    "        i+=1\n",
    "    eeList.append([api.getPos('X',moduleID),api.getPos('Y',moduleID)])\n",
    "    it, x_error, y_error, sqrt_error = ControlLoopWithNNWithoutCMAC(el[0],el[1])\n",
    "    x_error_list.append(x_error[-1])\n",
    "    y_error_list.append(y_error)\n",
    "    sqrt_error_list.append(sqrt_error)\n",
    "    itList.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = []\n",
    "for el in eeList:\n",
    "    if el[1] > 0:\n",
    "        yhat.append(0)\n",
    "    else:\n",
    "        yhat.append(1)\n",
    "%matplotlib qt \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x1 = linspace(0,len(targetList),len(targetList))\n",
    "ax.set_ylim([0, 21])\n",
    "plt.title(\"Iterations without CMAC, threshold {}, no lights\".format(err_treshold))\n",
    "plt.ylabel(\"Number of iterations\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "for i in range(len(targetList)):\n",
    "    # label = \"MotorAngle: {:.2f}°, {:.2f}°\\nTargetPos: {:.2f}, {:.2f}\".format(eeList[i][0],eeList[i][1],targetList[i][0],targetList[0][1])\n",
    "    label = \"{:.2f}° / {:.2f}°\\n{:.2f} / {:.2f}\".format(eeList[i][0],eeList[i][1],targetList[i][0],targetList[0][1])\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x1[i],itList[i]), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alig\n",
    "scatter1= ax.scatter(x1[:5],itList[:5], c = 'blue',label='End-Effector in (-90°,90°)')\n",
    "scatter2 = ax.scatter(x1[5:],itList[5:], c = 'red',label='End-Effector in (-90°,-90°)')\n",
    "legend = ax.legend(loc='upper left')\n",
    "ax.add_artist(legend)\n",
    "\n",
    "## PLOT ERROR ON X\n",
    "ax2=ax.twinx()\n",
    "ax2.scatter(x1,x_error_list, c = 'green', label='X-pixel error')\n",
    "ax2.set_ylim([-0.50, np.max(x_error_list)+1])\n",
    "ax2.set_ylabel(\"Pixel\",color=\"green\")\n",
    "legend = ax2.legend()\n",
    "ax2.add_artist(legend)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x1 = linspace(0,it+1,it+1)\n",
    "plt.title(\"Errors without CMAC\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "plt.plot(x1,x_error_list,label='x_error')\n",
    "plt.plot(x1,y_error_list,label='y_error')\n",
    "plt.plot(x1,sqrt_error_list,label='sqrt_error')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1dea23a291e1df5152587f0351bf339f3cd967bb9fb3b38297ae232315060d8e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('biocontrol': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
