{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import camera_tools as ct\n",
    "\n",
    "from FableAPI.fable_init import api\n",
    "api.setup(blocking=True)\n",
    "moduleids = api.discoverModules()\n",
    "print(\"Module IDs: \", moduleids)\n",
    "moduleID = moduleids[0]\n",
    "print(\"Battery level:\",api.getBattery(moduleID),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74871f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibrate the camera to detect green box, if you haven't done this calibration before\n",
    "low_green, high_green = ct.colorpicker()\n",
    "print(low_green)\n",
    "print(high_green)\n",
    "#Check whether the camera detects the green object properly\n",
    "cam = ct.prepare_camera()\n",
    "img = ct.capture_image(cam)\n",
    "ct.show_camera(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c21250",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = ct.prepare_camera()\n",
    "img = ct.capture_image(cam)\n",
    "ct.show_camera(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two files (if they were not already created) to collect data.\n",
    "if (not os.path.exists(\"xyCoords_2.csv\")):\n",
    "    f = open('xyCoords_2.csv', 'w')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[\"X\",\"Y\"]])\n",
    "    f.close()\n",
    "if (not os.path.exists(\"angles_2.csv\")):\n",
    "    f = open('angles_2.csv','w')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[\"Y_angle\"]])\n",
    "    f.close()\n",
    "\n",
    "#we use the collectData function to collect the data for training.\n",
    "    #we collect Y (angular) position of the end effector\n",
    "    #we collect x,y coordinates of the end effector in the camera image\n",
    "    #see the video final_project_guidance.mp4\n",
    "def collectData(desired_angle_change):\n",
    "    cam = ct.prepare_camera()\n",
    "    ct.show_camera(cam)\n",
    "    cam.release()\n",
    "    cam = ct.prepare_camera()\n",
    "    api.setPos(-90,90,moduleID)\n",
    "    api.sleep(1.5)\n",
    "    Y_angle_list = []\n",
    "    XY_coordinates_list = []\n",
    "    traversed_directions = 0\n",
    "    current_direction = 0     # 1 is for clockwise, 0 is for anticlockwise\n",
    "    traversedDirections = 0\n",
    "    num_of_iterations = (int)(np.round(360/desired_angle_change,1))\n",
    "    #Fable's Y arm traverse anticlockwise\n",
    "    if current_direction == 0:\n",
    "        for i in range(num_of_iterations):\n",
    "            img = ct.capture_image(cam)\n",
    "            x,y = ct.locate(img)\n",
    "            currentRobotYAng = (int)(np.round(api.getPos(1,moduleID),1))\n",
    "            Y_angle_list.append([currentRobotYAng])\n",
    "            XY_coordinates_list.append([x,y])\n",
    "            currentRobotYAng = currentRobotYAng - (desired_angle_change)\n",
    "            api.setPos(-90,currentRobotYAng,moduleID)\n",
    "            api.sleep(1.5)\n",
    "            if np.abs(currentRobotYAng) > 90:\n",
    "                current_direction = 1\n",
    "                traversedDirections = traversedDirections + 1\n",
    "                break\n",
    "    #Fable's Y Arm traverses clockwise\n",
    "    if current_direction == 1:\n",
    "        for i in range(num_of_iterations):\n",
    "            img = ct.capture_image(cam)\n",
    "            x,y = ct.locate(img)\n",
    "            currentRobotYAng = (int)(np.round(api.getPos(1,moduleID),1))\n",
    "            Y_angle_list.append([currentRobotYAng])\n",
    "            XY_coordinates_list.append([x,y])\n",
    "            currentRobotYAng = currentRobotYAng + (desired_angle_change)\n",
    "            api.setPos(-90,currentRobotYAng,moduleID)\n",
    "            api.sleep(1.5)\n",
    "            if np.abs(currentRobotYAng) > 90:\n",
    "                current_direction = 0\n",
    "                traversedDirections = traversedDirections + 1\n",
    "                break\n",
    "    if traversedDirections == 2:\n",
    "        cam.release()\n",
    "        #Save collected data to files\n",
    "        y_angle_file_ptr = open('angles_2.csv', 'a+', newline ='')\n",
    "        with y_angle_file_ptr:\n",
    "            writer = csv.writer(y_angle_file_ptr)\n",
    "            writer.writerows(Y_angle_list)\n",
    "        y_angle_file_ptr.close()\n",
    "        file_xycoords = open('xyCoords_2.csv', 'a+', newline ='')\n",
    "        with file_xycoords:\n",
    "            writer = csv.writer(file_xycoords)\n",
    "            writer.writerows(XY_coordinates_list)\n",
    "        file_xycoords.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.setPos(-90,90,moduleID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14beede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Call the CollectData() function with different values for 'desired_angle_change' argument and collect sufficient\n",
    "# sufficient amout \n",
    "# of data to angles_2.csv file and xycoords_2.csv file.\n",
    "# angles = [1, 2, 3, 5, 7, 10, 13, 15, 17, 19, 30, 45, 50, 70, 80]\n",
    "# for el in angles:\n",
    "collectData(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this function to calculate Y (angular) position errors \n",
    "# Y (angular) positions\n",
    "def readAngleFilesAndCollectErrors(fileName):\n",
    "    angleDataFrame = pd.read_csv(fileName)\n",
    "    desired_column = angleDataFrame.columns[0]\n",
    "    angle_error_list = []\n",
    "    for i in range(1,len(angleDataFrame)):\n",
    "        current_data_element = angleDataFrame[desired_column][i]\n",
    "        previous_data_element = angleDataFrame[desired_column][i-1]\n",
    "        #TODO: Calculate the Y (angular) position error(say current_error) as the difference between \n",
    "        # the current Y (angular) position and previous Y (angular) position\n",
    "        current_error = current_data_element - previous_data_element\n",
    "        #print(current_data_element,\" \", previous_data_element, \" \", current_error)\n",
    "        angle_error_list = angle_error_list + [current_error]\n",
    "    return angle_error_list\n",
    "\n",
    "#Use this function to calculate errors between x and y coordinates\n",
    "def readXYCoordsFilesAndCollectErrors(fileName):\n",
    "    xyCoordsDataFrame = pd.read_csv(fileName)\n",
    "    x_col_name = xyCoordsDataFrame.columns[0]\n",
    "    y_col_name = xyCoordsDataFrame.columns[1]\n",
    "    x_pos_error_list = []\n",
    "    y_pos_error_list = []\n",
    "    for i in range(1,len(xyCoordsDataFrame)):\n",
    "        current_data_element_x = xyCoordsDataFrame[x_col_name][i]\n",
    "        current_data_element_y = xyCoordsDataFrame[y_col_name][i]\n",
    "        previous_data_element_x = xyCoordsDataFrame[x_col_name][i-1]\n",
    "        previous_data_element_y = xyCoordsDataFrame[y_col_name][i-1]\n",
    "        error_x_pos = current_data_element_x - previous_data_element_x \n",
    "        error_y_pos = current_data_element_y - previous_data_element_y\n",
    "        x_pos_error_list = x_pos_error_list + [error_x_pos]\n",
    "        y_pos_error_list = y_pos_error_list + [error_y_pos] \n",
    "    return [x_pos_error_list,y_pos_error_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d283c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the provided files and load the calculated errors into to appropriate lists as follows\n",
    "angle_error_list_1 = readAngleFilesAndCollectErrors(\"angles_1.csv\")\n",
    "x_pos_error_list_1,y_pos_error_list_1 = readXYCoordsFilesAndCollectErrors(\"xyCoords_1.csv\")\n",
    "\n",
    "#merge both angle_error_list_1 and angle_error_list_2 to a single list and make it a numpy array called 'angle_error_array'\n",
    "angle_error_array = np.array(angle_error_list_1)\n",
    "#merge both x_pos_error_list_1 and x_pos_error_list_2 to a single list and make it a numpy array called 'x_coord_error_array'\n",
    "x_coord_error_array = np.array(x_pos_error_list_1)\n",
    "#merge both y_pos_error_list_1 and y_pos_error_list_2 to a single list and make it a numpy array called 'y_coord_error_array'\n",
    "y_coord_error_array = np.array(y_pos_error_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a24914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use 80% of the collected data  as the training set and 20% of the collected data as test set.\n",
    "#TODO: Assign different propotions of the collected data set and test set and check how the test set error varies of the \n",
    "#Neural Network\n",
    "data =  np.vstack((x_coord_error_array,y_coord_error_array)).T\n",
    "target = np.vstack(angle_error_array)\n",
    "data_input_tensor = torch.tensor(data.tolist()).float()\n",
    "data_target_tensor = torch.tensor(target.tolist()).float()\n",
    "data_with_target = torch.cat((data_input_tensor,data_target_tensor),1)\n",
    "#TODO: what is the importance of using DataLoader utility function here?\n",
    "loader= torch.utils.data.DataLoader(data_with_target,\n",
    "                                     batch_size=data_with_target.size()[0], shuffle=True,\n",
    "                                     num_workers=0)\n",
    "#training set\n",
    "train_set = []\n",
    "#test set\n",
    "test_set = []\n",
    "for i in iter(loader):\n",
    "    train_set_index = (int)(np.round(i.shape[0]*0.8))\n",
    "    train_set = i[:train_set_index,:]\n",
    "    test_set = i[train_set_index:,:]\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70582f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Neural Network Model\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self,n_feature,n_hidden1,n_hidden2,n_output):\n",
    "        super(NN,self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature,n_hidden1)\n",
    "        # self.do1 = torch.nn.Dropout(0.15)\n",
    "        #self.relu1 = torch.nn.LeakyReLU()\n",
    "        #self.bn1 = torch.nn.BatchNorm1d(n_hidden1,affine=False)\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden1,n_hidden2)\n",
    "        #self.bn2 = torch.nn.BatchNorm1d(n_hidden2,affine=False)\n",
    "        #self.relu2 = torch.nn.LeakyReLU()\n",
    "        # self.do2 = torch.nn.Dropout(0.1)\n",
    "        self.predict = torch.nn.Linear(n_hidden2,n_output)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.hidden1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6985a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_inputs = train_set[:,:2]\n",
    "#TODO: calculate the mean value of the train_set_inputs.\n",
    "mean_of_train_input = torch.mean(train_set_inputs,0)\n",
    "#standard deviation of the train set inputs.\n",
    "std_of_the_train_input = torch.std(train_set_inputs,0)\n",
    "#here we normalize the inputs of the neural network. What is the importance of that?\n",
    "normalized_train_set_inputs = (train_set_inputs - mean_of_train_input)/std_of_the_train_input\n",
    "#targets of the training set\n",
    "train_set_targets = train_set[:,2][:,np.newaxis]\n",
    "print(normalized_train_set_inputs.shape)\n",
    "print(train_set_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Neural Network\n",
    "# model = NN(n_feature=2,n_hidden1=17,n_hidden2=7, n_output=1)\n",
    "# model = NN(n_feature=2,n_hidden1=31,n_hidden2=13, n_output=1)\n",
    "\n",
    "n_hidden1 = 17\n",
    "n_hidden2 = 7\n",
    "lr = 0.15\n",
    "model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "# model = NN(n_feature=2,n_hidden1=70,n_hidden2=49, n_output=1)\n",
    "\n",
    "\n",
    "#Define loss function : \n",
    "# here we use Mean Square Error as the loss function\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "#Define the optimizer that should be used in training the Neural Network.\n",
    "# Here 'lr' is the learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "#TODO: train the Neural network model by changing the hyper parameters such as learning rate, number of epochs, number of neurons in hidden layers of the neural network.\n",
    "# What is the minimum mean square error that you can achieve as your neural network converges for the training set.\n",
    "#  (you will be able to achive a MSE of less than 10 as the Neural network converges.)\n",
    "num_epochs = 20000\n",
    "losslist = []\n",
    "for _ in range(num_epochs):\n",
    "    prediction = model(normalized_train_set_inputs) # Forward pass prediction. Saves intermediary values required for backwards pass\n",
    "    loss = loss_func(prediction, train_set_targets) # Computes the loss for each example, using the loss function defined above\n",
    "    optimizer.zero_grad() # Clears gradients from previous iteration\n",
    "    loss.backward() # Backpropagation of errors through the network\n",
    "    optimizer.step() # Updating weights\n",
    "    # print(\"prediction =\",prediction)\n",
    "    print(\"Loss: \", loss.detach().numpy())\n",
    "    losslist.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3192e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the mean square error in each epoch/iteration\n",
    "%matplotlib qt\n",
    "plt.plot(np.arange(len(losslist)),losslist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best neural network model you have obtained.\n",
    "torch.save(model.state_dict(), 'best_nn_model_DEMO.pth')\n",
    "torch.save(n_hidden1, 'best_nn_hidden1_DEMO.pth')\n",
    "torch.save(n_hidden2, 'best_nn_hidden2_DEMO.pth')\n",
    "#Save the mean and standard deviation of the train set inputs because we need to use them at test time.\n",
    "torch.save(mean_of_train_input, 'best_mean_DEMO.pth')\n",
    "torch.save(std_of_the_train_input, 'best_std_DEMO.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab535de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the your best neural network model with saved parameters\n",
    "n_hidden1 = torch.load('best_nn_hidden.pth')\n",
    "n_hidden2 = torch.load('best_nn_hidden22.pth')\n",
    "lr = torch.load('best_nn_lr.pth')\n",
    "NN_model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "NN_model.load_state_dict(torch.load('best_nn_model1.pth'))\n",
    "#TODO: Extract inputs of the test_set\n",
    "test_set_inputs = test_set[:,:2]\n",
    "#TODO: Extract test set targets from the test_set\n",
    "test_set_targets = test_set[:,2][:,np.newaxis]\n",
    "#TODO: Normalize test set inputs by using the mean and standard deviation of the inputs of the training set\n",
    "mean_training_inputs = torch.load('best_mean1.pth')\n",
    "std_training_inputs = torch.load('best_std1.pth')\n",
    "normalized_test_set_inputs = (test_set_inputs - mean_training_inputs)/std_training_inputs\n",
    "#TODO: feed the normalized test set inputs to the Neural Network model and obtain the prediction for the test set.\n",
    "prediction_test = NN_model(normalized_test_set_inputs)\n",
    "print(prediction_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84590f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the prediction error of the test set\n",
    "test_set_prediction_error = prediction_test - test_set_targets\n",
    "plt.plot(np.arange(len(test_set_prediction_error.tolist())),test_set_prediction_error.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the example model trained with about 600 data, from a test set of 165 samples,\n",
    "# 159 samples are predicted with prediction error less than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Based on the prediction error of the test set, you can try to train the neural network again by changing the hyper parameters mentioned above.\n",
    "# Also Try to add Dropout layers to the Neural network and check whether test prediction errors can be reduced further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6b6a9",
   "metadata": {},
   "source": [
    "Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96818edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab an image and locate the largest green object:\n",
    "def getPos():\n",
    "    cam = ct.prepare_camera()\n",
    "    while True:\n",
    "        img = ct.capture_image(cam)\n",
    "        x, y = ct.locate(img)\n",
    "        if x is not None:\n",
    "            break\n",
    "    # print(\"Now the camera is done adjusting!\")\n",
    "    X,Y = [],[] \n",
    "    for _ in range(10):\n",
    "        img = ct.capture_image(cam)\n",
    "        x, y = ct.locate(img)\n",
    "        # print(x, y)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    cam.release()\n",
    "    X = np.rint(np.mean(np.asarray(X))).astype(int)\n",
    "    Y = np.rint(np.mean(np.asarray(Y))).astype(int)\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3979d",
   "metadata": {},
   "source": [
    "# DETECTING THE OBJECT AT TESTING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8744fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we implement the control loop which is having Neural Network as the controller.\n",
    "#In this case we donot integrate CMAC to the control loop\n",
    "def ControlLoopWithNNWithoutCMAC(target__x_coordinate,target__y_coordinate):\n",
    "    \n",
    "    number_of_iterations_for_convergence = 0\n",
    "    #TODO:Intialize your best neural network model and load the saved paramemeters\n",
    "    NN_model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "    NN_model.load_state_dict(torch.load('best_nn_model1.pth'))\n",
    "    mean_training_inputs = torch.load('best_mean1.pth')\n",
    "    std_training_inputs = torch.load('best_std1.pth')\n",
    "\n",
    "    #TODO: Obtain the x and y coodinates of the green box placed on the end effector of the robot\n",
    "    robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "    # Here we loop for 50 iterations assuming that \n",
    "    # the controller should achieve the desired target within atmost 50 iterations\n",
    "    err_treshold = 20\n",
    "    for i in range(10):\n",
    "        print(\"Curr_pos: \",robot_current_X_pos, robot_current_Y_pos)\n",
    "        x_coord_error = target__x_coordinate - robot_current_X_pos\n",
    "        y_coord_error = target__y_coordinate - robot_current_Y_pos\n",
    "        print(\"Error_y: \",y_coord_error)\n",
    "        #Here if the errors are less than twenty pixels we assume robot reaches the target. \n",
    "        # However you can choose any reasonable threshold value instead of 20.\n",
    "        if (np.abs(x_coord_error) < err_treshold and np.abs(y_coord_error) < err_treshold):\n",
    "            print(\"Number of iterations for convergence = \", number_of_iterations_for_convergence)\n",
    "            break\n",
    "\n",
    "        # Normalize the input to the Neural network model using meaning and variance of the training set inputs\n",
    "        xy_input_nn_model = torch.tensor([x_coord_error,y_coord_error]).float()\n",
    "        normalize_xy_input_nn_model = (xy_input_nn_model - mean_training_inputs)/std_training_inputs\n",
    "        # Predict \n",
    "        prediction_for_Y_pos_increment = NN_model(normalize_xy_input_nn_model)\n",
    "        print(\"Increment_y: \",prediction_for_Y_pos_increment[0])\n",
    "        # Get current motorY angle\n",
    "        currAngY = api.getPos('Y',moduleID)\n",
    "        print(\"Curr_angleY: \",currAngY)\n",
    "        # Set the next position of the robot to (-90,robot_next_Y_pos) using the setPos function of the fable.\n",
    "        api.setPos(-90,currAngY - prediction_for_Y_pos_increment, moduleID)\n",
    "        api.sleep(1.5)\n",
    "        print(\"AngleY after: \",api.getPos('Y',moduleID))\n",
    "        # Get current position of the robot in the camera frame\n",
    "        robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "        number_of_iterations_for_convergence = number_of_iterations_for_convergence + 1\n",
    "    return number_of_iterations_for_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Detect the target object and obtain the coordinates of the object in the image\n",
    "api.setPos(-90,0,moduleID)\n",
    "# cam = ct.prepare_camera()\n",
    "# img = ct.capture_image(cam)\n",
    "# ct.show_camera(cam)\n",
    "# target_x, target_y = getPos()\n",
    "# print(target_x,target_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519af766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Call the control loop for a target which is detected. Record the number of iterations that the control loop spent for convergence.\n",
    "iteretionList = []\n",
    "# iteretionList.append(ControlLoopWithNNWithoutCMAC(torch.tensor(target_x).float(),torch.tensor(target_y).float()))\n",
    "iteretionList.append(ControlLoopWithNNWithoutCMAC(target_x,target_y))\n",
    "\n",
    "#TODO: change your target location and try again. You may change the target 4-5 times and check how the control loop work.\n",
    "#Record the number of iterations that the control loop spent for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now integrate the CMAC to the previous control loop which had only the Neural Network. \n",
    "#The implementation of the CMAC can be found in code given for second week exercises.\n",
    "#TODO: Implement the control loop with both neural network and CMAC. \n",
    "from cmac2 import CMAC\n",
    "# Initialize CMAC\n",
    "n_rfs = 3\n",
    "xmin = [172,172]\n",
    "xmax = [485,485]\n",
    "cmac = CMAC(n_rfs, xmin, xmax, 0.1)\n",
    "def ControlLoopWithBothNNandCMAC(target__x_coordinate,target__y_coordinate):\n",
    "    number_of_iterations_for_convergence = 0\n",
    "    \n",
    "    # Initialize NN    \n",
    "    NN_model = NN(n_feature=2,n_hidden1=n_hidden1,n_hidden2=n_hidden2, n_output=1)\n",
    "    NN_model.load_state_dict(torch.load('best_nn_model.pth'))\n",
    "    mean_training_inputs = torch.load('best_mean.pth')\n",
    "    std_training_inputs = torch.load('best_std.pth')\n",
    "    # Initialize CMAC\n",
    "    n_rfs = 11\n",
    "    xmin = [-np.pi,-np.pi]\n",
    "    xmax = [np.pi,np.pi]\n",
    "    cmac = CMAC(n_rfs, xmin, xmax, 1e-3)\n",
    "    # Get x and y coodinates of the green box placed on the end effector of the robot\n",
    "    robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "    \n",
    "    # Here we loop for 50 iterations assuming that \n",
    "    # the controller should achieve the desired target within atmost 50 iterations\n",
    "    err_treshold = 20\n",
    "    for i in range(50):\n",
    "        print(\"Curr_pos: \",robot_current_X_pos, robot_current_Y_pos)\n",
    "        x_coord_error = target__x_coordinate - robot_current_X_pos\n",
    "        y_coord_error = target__y_coordinate - robot_current_Y_pos\n",
    "        print(\"Error_y: \",y_coord_error)\n",
    "        if (np.abs(x_coord_error) < err_treshold and np.abs(y_coord_error) < err_treshold):\n",
    "            print(\"Number of iterations for convergence = \", number_of_iterations_for_convergence)\n",
    "            break\n",
    "        xy_input_nn_model = [x_coord_error,y_coord_error]\n",
    "        # Normalize the input to the Neural network model using meaning and variance of the training set inputs.\n",
    "        normalize_xy_input_nn_model = (xy_input_nn_model - mean_training_inputs)/std_training_inputs\n",
    "        deltaY_nn = NN_model(normalize_xy_input_nn_model)\n",
    "        print(\"DeltaY_nn: \",deltaY_nn)\n",
    "        # Update CMAC \n",
    "        deltaY_cmac = cmac.predict([robot_current_Y_pos, target__y_coordinate])\n",
    "        print(\"DeltaY_cmac: \",deltaY_cmac)\n",
    "        cmac.learn(deltaY_nn)\n",
    "        # Get current motorY angle\n",
    "        currAngY = api.getPos('Y',moduleID)\n",
    "        print(\"Curr_angleY: \",currAngY)\n",
    "        # Set new angleY\n",
    "        robot_next_Y_pos = deltaY_nn + deltaY_cmac + currAngY\n",
    "        api.setPos(-90,robot_next_Y_pos, moduleID)\n",
    "        api.sleep(1.5)\n",
    "        print(\"AngleY after: \",api.getPos('Y',moduleID))\n",
    "        # Get current position of the robot in the camera frame\n",
    "        robot_current_X_pos, robot_current_Y_pos = getPos()\n",
    "        number_of_iterations_for_convergence = number_of_iterations_for_convergence + 1\n",
    "    return number_of_iterations_for_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compare the number of iteration it takes for convergence in the control loop with \n",
    "# neural network only and with both CMAC and neural network."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97b1ca7657afa4cca8b89ccd445cd43dbad4b1535d3709ba624a8852d37759e0"
  },
  "kernelspec": {
   "display_name": "Python [conda env:biocontrol] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
